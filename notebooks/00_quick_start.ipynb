{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start: LLaMA 3 Finance Robustness Benchmarking\n",
    "\n",
    "**Author**: Emmanuel Kwadwo Kusi  \n",
    "**Project**: Benchmarking LLaMA 3 Robustness in Finance via Prompt Perturbations\n",
    "\n",
    "This notebook demonstrates the complete workflow for evaluating LLM robustness using semantic entropy.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. **Setup**: Import libraries and configure environment\n",
    "2. **Data**: Load and explore financial datasets\n",
    "3. **Prompts**: Generate paraphrased variants\n",
    "4. **Sampling**: Run LLaMA 3 inference\n",
    "5. **Analysis**: Compute semantic entropy and robustness\n",
    "6. **Visualization**: Create insights plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = Path('../data')\n",
    "RESULTS_DIR = Path('../results')\n",
    "\n",
    "# Create directories\n",
    "for dir_path in [DATA_DIR / 'raw', DATA_DIR / 'processed', DATA_DIR / 'prompts',\n",
    "                 RESULTS_DIR / 'raw_outputs', RESULTS_DIR / 'metrics', RESULTS_DIR / 'figures']:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"✓ Directories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Acquisition and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data modules\n",
    "from data.download_datasets import DatasetDownloader\n",
    "from data.preprocess import FinanceDataPreprocessor\n",
    "\n",
    "# Download datasets (first time only)\n",
    "print(\"Downloading datasets...\")\n",
    "downloader = DatasetDownloader(output_dir=str(DATA_DIR / 'raw'))\n",
    "\n",
    "# Download FinQA\n",
    "finqa_df = downloader.download_finqa()\n",
    "print(f\"FinQA: {len(finqa_df)} samples\")\n",
    "\n",
    "# Generate summary\n",
    "summary = downloader.generate_summary()\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "print(\"Preprocessing datasets...\")\n",
    "preprocessor = FinanceDataPreprocessor(\n",
    "    input_dir=str(DATA_DIR / 'raw'),\n",
    "    output_dir=str(DATA_DIR / 'processed')\n",
    ")\n",
    "\n",
    "# Process FinQA\n",
    "processed_df = preprocessor.process_finqa(max_samples=1000)\n",
    "print(f\"Processed: {len(processed_df)} samples\")\n",
    "\n",
    "# Extract seed prompts\n",
    "seed_prompts = preprocessor.extract_seed_prompts(n_prompts=10)\n",
    "print(f\"Extracted {len(seed_prompts)} seed prompts\")\n",
    "\n",
    "# Display sample seeds\n",
    "display(seed_prompts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prompt Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import prompt generator\n",
    "from models.prompt_generator import PromptParaphraser\n",
    "\n",
    "# Initialize paraphraser\n",
    "print(\"Loading paraphrase models...\")\n",
    "paraphraser = PromptParaphraser(paraphrase_method='backtranslation')\n",
    "\n",
    "print(\"✓ Paraphraser ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate variants for first seed prompt\n",
    "example_prompt = seed_prompts.iloc[0]['question']\n",
    "print(f\"Original prompt: {example_prompt}\")\n",
    "print(\"\\nGenerating variants...\")\n",
    "\n",
    "variants = paraphraser.generate_variants(\n",
    "    prompt=example_prompt,\n",
    "    num_variants=5,\n",
    "    min_similarity=0.85\n",
    ")\n",
    "\n",
    "# Display variants\n",
    "for i, variant in enumerate(variants):\n",
    "    print(f\"\\nVariant {i}: (similarity: {variant['similarity']:.3f})\")\n",
    "    print(f\"  {variant['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LLM Sampling (Demo)\n",
    "\n",
    "**Note**: This section demonstrates the sampling process. Running the full LLaMA 3 inference requires significant computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run actual LLaMA 3 sampling\n",
    "# from models.llm_runner import LLaMARunner\n",
    "\n",
    "# # Initialize runner\n",
    "# runner = LLaMARunner(\n",
    "#     model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "#     load_in_4bit=True\n",
    "# )\n",
    "\n",
    "# # Sample responses\n",
    "# responses = runner.sample_multiple(\n",
    "#     prompt=example_prompt,\n",
    "#     num_samples=5,\n",
    "#     temperature=0.7\n",
    "# )\n",
    "\n",
    "# for i, response in enumerate(responses):\n",
    "#     print(f\"\\nResponse {i+1}:\")\n",
    "#     print(response)\n",
    "\n",
    "print(\"Skipping LLM sampling in demo mode.\")\n",
    "print(\"To run full pipeline, use: python run_pipeline.sh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Semantic Entropy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample outputs (if available)\n",
    "outputs_path = RESULTS_DIR / 'raw_outputs' / 'llama3_outputs.csv'\n",
    "\n",
    "if outputs_path.exists():\n",
    "    outputs_df = pd.read_csv(outputs_path)\n",
    "    print(f\"Loaded {len(outputs_df)} outputs\")\n",
    "    display(outputs_df.head())\n",
    "else:\n",
    "    print(\"No outputs found. Run full pipeline first.\")\n",
    "    # Create sample data for demonstration\n",
    "    outputs_df = pd.DataFrame({\n",
    "        'family_id': ['family_001'] * 20,\n",
    "        'variant_id': [0] * 20,\n",
    "        'sample_id': range(20),\n",
    "        'prompt_text': [example_prompt] * 20,\n",
    "        'response': [f\"Sample response {i}\" for i in range(20)]\n",
    "    })\n",
    "    print(\"Using sample data for demonstration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute semantic entropy\n",
    "from evaluation.entropy_calculator import SemanticEntropy\n",
    "\n",
    "print(\"Initializing entropy calculator...\")\n",
    "calculator = SemanticEntropy(\n",
    "    embedder_model='sentence-transformers/all-MiniLM-L6-v2',\n",
    "    clustering_method='hdbscan'\n",
    ")\n",
    "\n",
    "if outputs_path.exists():\n",
    "    print(\"Computing entropy...\")\n",
    "    entropy_df = calculator.compute_all(\n",
    "        outputs_df=outputs_df,\n",
    "        output_dir=str(RESULTS_DIR / 'metrics')\n",
    "    )\n",
    "    display(entropy_df.head())\n",
    "else:\n",
    "    print(\"Skipping entropy computation (no real outputs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Robustness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute robustness\n",
    "from evaluation.robustness_metric import RobustnessCalculator\n",
    "\n",
    "calc = RobustnessCalculator()\n",
    "\n",
    "if outputs_path.exists():\n",
    "    robustness_df = calc.compute_from_entropy_file(\n",
    "        entropy_file=str(RESULTS_DIR / 'metrics' / 'entropy_detailed.csv'),\n",
    "        output_dir=str(RESULTS_DIR / 'metrics')\n",
    "    )\n",
    "    display(robustness_df.head())\n",
    "else:\n",
    "    print(\"Skipping robustness computation (no entropy data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "from visualization.plot_results import RobustnessVisualizer\n",
    "\n",
    "visualizer = RobustnessVisualizer(output_dir=str(RESULTS_DIR / 'figures'))\n",
    "\n",
    "if outputs_path.exists():\n",
    "    print(\"Generating plots...\")\n",
    "    \n",
    "    # Entropy heatmap\n",
    "    visualizer.plot_entropy_heatmap(entropy_df)\n",
    "    \n",
    "    # Robustness distribution\n",
    "    visualizer.plot_robustness_distribution(robustness_df)\n",
    "    \n",
    "    # Entropy vs Robustness\n",
    "    visualizer.plot_entropy_vs_robustness(robustness_df)\n",
    "    \n",
    "    print(\"✓ Visualizations saved to results/figures/\")\n",
    "else:\n",
    "    print(\"Run full pipeline to generate visualizations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete workflow:\n",
    "\n",
    "1. ✅ Dataset acquisition and preprocessing\n",
    "2. ✅ Prompt variant generation via paraphrasing\n",
    "3. ⏭️ LLM sampling (requires full pipeline)\n",
    "4. ⏭️ Semantic entropy computation\n",
    "5. ⏭️ Robustness metric calculation\n",
    "6. ⏭️ Visualization generation\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To run the full pipeline:\n",
    "\n",
    "```bash\n",
    "# Linux/Mac\n",
    "bash run_pipeline.sh\n",
    "\n",
    "# Windows\n",
    "run_pipeline.bat\n",
    "```\n",
    "\n",
    "Or use the Python scripts individually:\n",
    "\n",
    "```bash\n",
    "python src/data/download_datasets.py\n",
    "python src/data/preprocess.py\n",
    "python src/models/prompt_generator.py\n",
    "python src/models/llm_runner.py\n",
    "python src/evaluation/entropy_calculator.py\n",
    "python src/evaluation/robustness_metric.py\n",
    "python src/visualization/plot_results.py\n",
    "```\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **Documentation**: `docs/METHODOLOGY.md`\n",
    "- **Configuration**: `config/config.yaml`\n",
    "- **Full README**: `../README.md`\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: Emmanuel Kwadwo Kusi  \n",
    "**GitHub**: [Your GitHub Link]  \n",
    "**LinkedIn**: [Your LinkedIn Profile]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
